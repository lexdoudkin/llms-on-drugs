LLMs on Drugs: Language Models Are Few-Shot Consumers

Abstract:
Large language models (LLMs) are sensitive to subtle changes in prompt framing, often exhibiting significant behavioral and stylistic shifts. In this study, we explore how simulated psychoactive states—induced purely through linguistic priming—affect model reasoning and creativity. We introduce a simple intervention: prefixing each prompt with “You are on [drug]”, where the condition is one of three archetypal psychoactive framings—LSD, cocaine, alcohol, or cannabis—plus a neutral control. Using a fixed instruction-tuned model (gpt-5-mini), we evaluate performance across a well known LLM benchmark on overall intelligence .

Our findings suggest that LLMs, like human minds, can be “intoxicated” through context alone—few-shot consumers whose cognition depends less on chemistry than on language itself.